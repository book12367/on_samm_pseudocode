算法：SAMM微表情识别模型推理算法

// 全局配置参数
CONFIG = {
    data_dir: "E:\\LW\\SAMM_videos",         // 数据集路径
    use_refined_landmarks: 真,            // 是否使用细节优化关键点（假=468，真=478）
    target_length: 20,                      // 统一序列长度
    batch_size: 2,                         // 训练批大小
    epochs: 100,                           // 最大训练轮次
    model_path: "me_model_tf.h5",          // 模型保存路径
    min_frames: 10,                        // 实时检测最小帧数
    is_training: 假,                    // 是否为训练模式
    AugTimes: 5                            // 数据增强次数 训练模式生效
}

// 计算输入维度
LANDMARK_POINTS = 478 若 CONFIG["use_refined_landmarks"] 为真 否则 468
CONFIG["input_shape"] = (CONFIG["target_length"], LANDMARK_POINTS * 3)

// 特征提取器类（用于推理）
类 特征提取器:
    初始化():
        face_mesh = mp.解决方案.面部网格.面部网格(
            static_image_mode=假,
            max_num_faces=1,
            refine_landmarks=CONFIG["use_refined_landmarks"],
            min_detection_confidence=0.5)
    
    处理视频(视频路径):
        cap = cv2.视频捕获(视频路径)
        landmarks_seq = []
        
        当 cap.isOpened() 为真 时:
            ret, frame = cap.读取()
            若 不是 ret:
                跳出循环
            
            results = face_mesh.处理(cv2.转换颜色空间(frame, cv2.COLOR_BGR2RGB))
            若 results.multi_face_landmarks 存在:
                landmarks = 数组([[lm.x, lm.y, lm.z]
                                    对于 lm 在 results.multi_face_landmarks[0].地标]):
                landmarks_seq.添加(landmarks.展平())
            否则:
                // 记录未检测到面部的帧数
                继续
        
        cap.释放()
        返回 数组(landmarks_seq)

// 序列处理器类（用于推理）
类 序列处理器:
    初始化():
        target_length = CONFIG["target_length"]
        selected_indices = [x 对于 x 在 范围(LANDMARK_POINTS)]
    
    对齐序列(序列):
        若 序列.长度() < 2:
            返回 零数组((target_length, 序列.形状[1]))
        
        // 提取关键点特征用于DTW对齐
        selected_features = 序列[:, selected_indices].重塑(长度(序列), -1)
        
        // 生成参考序列（使用线性插值）
        original_length = 长度(序列)
        x_orig = 线性空间(0, 1, original_length)
        x_new = 线性空间(0, 1, target_length)
        R_selected = 零数组((target_length, selected_features.形状[1]))
        
        对于 dim 在 范围(selected_features.形状[1]):
            f = 插值函数(x_orig, selected_features[:, dim], 类型='线性', 填充值="外推")
            R_selected[:, dim] = f(x_new)
        
        // 计算DTW路径
        _, path = 快速动态时间规整(selected_features, R_selected, 距离=欧几里得距离)
        
        // 根据路径构建对齐后的序列
        aligned = 零数组((target_length, 序列.形状[1]))
        counts = 零数组(target_length)
        
        对于 s_idx, r_idx 在 path:
            aligned[r_idx] += 序列[s_idx]
            counts[r_idx] += 1
        
        // 处理未对齐的位置并归一化
        counts[counts == 0] = 1  // 避免除以零
        aligned /= counts[:, 新轴]
        
        返回 aligned
    
    标准化(序列):
        mean = 平均值(序列, 轴=0)
        std = 标准差(序列, 轴=0)
        返回 (序列 - mean) / (std + 1e-8)
    
    处理(序列):
        processed = 对齐序列(序列)
        返回 标准化(processed)

// 加载标签函数
加载标签():
    全局 类  // 声明为全局变量以便其他函数使用
    
    categories = 排序([d 对于 d 在 列表目录(CONFIG["data_dir"])
                        若 os.路径.是目录(连接路径(CONFIG["data_dir"], d))])
    label_encoder = 标签编码器().拟合(categories)
    类 = label_encoder.类_

// 单视频检测函数
检测单视频(视频路径, 模型路径=空, 显示处理进度=真):
    // 初始化配置
    模型路径 = 模型路径 或 CONFIG["model_path"]
    extractor = 特征提取器()
    processor = 序列处理器()
    
    // 结果字典
    result = {
        "状态": "成功",
        "预测类别": 空,
        "置信度": 0.0,
        "类别概率": {},
        "错误": 空,
        "警告": []
    }
    
    尝试:
        // 检查文件存在性
        若 不是 os.路径.存在(视频路径):
            抛出 文件未找到错误(f"视频文件不存在: {视频路径}")
        
        // 加载模型
        若 不是 os.路径.存在(模型路径):
            抛出 值错误(f"模型文件不存在: {模型路径}")
        model = tf.keras.模型.加载模型(模型路径)
        
        // 处理视频
        cap = cv2.视频捕获(视频路径)
        total_frames = 整数(cap.获取(cv2.CAP_PROP_FRAME_COUNT))
        landmarks_seq = []
        missed_frames = 0
        
        // 带进度条的处理
        progress = tqdm(总数=total_frames, 描述="处理视频帧", 禁用=不是 显示处理进度)
        当 cap.isOpened() 为真 时:
            ret, frame = cap.读取()
            若 不是 ret:
                跳出循环
            
            // 面部关键点检测
            results = extractor.face_mesh.处理(cv2.转换颜色空间(frame, cv2.COLOR_BGR2RGB))
            若 results.multi_face_landmarks 存在:
                landmarks = 数组([[lm.x, lm.y, lm.z]
                                    对于 lm 在 results.multi_face_landmarks[0].地标]):
                landmarks_seq.添加(landmarks.展平())
            否则:
                missed_frames += 1
            
            progress.更新(1)
        cap.释放()
        progress.关闭()
        
        // 检查有效帧数
        若 长度(landmarks_seq) < CONFIG["min_frames"]:
            抛出 值错误("有效帧数不足，无法进行分析")
        
        // 处理序列
        aligned_seq = processor.对齐序列(数组(landmarks_seq))
        processed_seq = processor.标准化(aligned_seq)
        
        // 执行预测
        predictions = model.预测(processed_seq[新轴, ...], 详细=0)[0]
        predicted_idx = 最大值索引(predictions)
        
        // 构建结果
        result.更新({
            "预测类别": 类[predicted_idx],
            "置信度": 浮点(最大值(predictions)),
            "类别概率": {cls: 浮点(prob) 对于 cls, prob 在 zip(类, predictions)},
            "警告": [f"检测丢失{missed_frames}帧"] 若 missed_frames > 0 否则 []
        })
    
    除了 异常 as e:
        result.更新({
            "状态": "错误",
            "错误": str(e)
        })
    
    // 添加诊断信息
    result["诊断"] = {
        "视频路径": 视频路径,
        "总帧数": total_frames,
        "有效帧数": 长度(landmarks_seq),
        "处理时间": progress.格式字典["已用时间"] 若 显示处理进度 否则 空
    }
    
    返回 result

// 主执行流程
主函数():
    // 加载类别标签
    加载标签()
    
    // 执行检测
    start_time = 时间.时间()
    test_result = 检测单视频(
        视频路径=r"E:\LW\SAMM_videos\Contempt\014_5_2.mp4",
        显示处理进度=真
    )
    打印("检测时间：", 时间.时间() - start_time)
    
    // 打印结果
    打印("\n检测结果：")
    若 test_result["状态"] == "成功":
        打印(f"预测类别: {test_result['预测类别']}")
        打印(f"置信度: {test_result['置信度']:.2%}")
        打印("\n详细概率分布：")
        对于 cls, prob 在 test_result["类别概率"].项目():
            打印(f"  {cls}: {prob:.2%}")
    否则:
        打印(f"检测失败: {test_result['错误']}")
    
    // 显示警告信息
    若 test_result["警告"]:
        打印("\n警告信息：")
        对于 warn 在 test_result["警告"]:
            打印(f"  - {warn}")
