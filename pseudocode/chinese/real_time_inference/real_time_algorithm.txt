算法：SAMM微表情识别实时检测算法

// 全局配置参数
CONFIG = {
    data_dir: "E:\\LW\\SAMM_videos",         // 数据集路径
    use_refined_landmarks: 真,            // 是否使用细节优化关键点（假=468，真=478）
    target_length: 20,                      // 统一序列长度
    batch_size: 2,                         // 训练批大小
    epochs: 100,                           // 最大训练轮次
    model_path: "me_model_tf.h5",          // 模型保存路径
    min_frames: 10,                        // 实时检测最小帧数
    is_training: 假,                    // 是否为训练模式
    AugTimes: 5                            // 数据增强次数 训练模式生效
}

// 计算输入维度
LANDMARK_POINTS = 478 若 CONFIG["use_refined_landmarks"] 为真 否则 468
CONFIG["input_shape"] = (CONFIG["target_length"], LANDMARK_POINTS * 3)

// 特征提取器类（用于实时检测）
类 特征提取器:
    初始化():
        face_mesh = mp.解决方案.面部网格.面部网格(
            static_image_mode=假,
            max_num_faces=1,
            refine_landmarks=CONFIG["use_refined_landmarks"],
            min_detection_confidence=0.5)
    
    处理单帧(帧):
        results = face_mesh.处理(cv2.转换颜色空间(帧, cv2.COLOR_BGR2RGB))
        若 results.multi_face_landmarks 存在:
            landmarks = 数组([[lm.x, lm.y, lm.z]
                                对于 lm 在 results.multi_face_landmarks[0].地标]):
            返回 landmarks.展平()
        返回 空

// 序列处理器类（用于实时检测）
类 序列处理器:
    初始化():
        target_length = CONFIG["target_length"]
        selected_indices = [x 对于 x 在 范围(LANDMARK_POINTS)]
    
    对齐序列(序列):
        若 序列.长度() < 2:
            返回 零数组((target_length, 序列.形状[1]))
        
        // 提取关键点特征用于DTW对齐
        selected_features = 序列[:, selected_indices].重塑(长度(序列), -1)
        
        // 生成参考序列（使用线性插值）
        original_length = 长度(序列)
        x_orig = 线性空间(0, 1, original_length)
        x_new = 线性空间(0, 1, target_length)
        R_selected = 零数组((target_length, selected_features.形状[1]))
        
        对于 dim 在 范围(selected_features.形状[1]):
            f = 插值函数(x_orig, selected_features[:, dim], 类型='线性', 填充值="外推")
            R_selected[:, dim] = f(x_new)
        
        // 计算DTW路径
        _, path = 快速动态时间规整(selected_features, R_selected, 距离=欧几里得距离)
        
        // 根据路径构建对齐后的序列
        aligned = 零数组((target_length, 序列.形状[1]))
        counts = 零数组(target_length)
        
        对于 s_idx, r_idx 在 path:
            aligned[r_idx] += 序列[s_idx]
            counts[r_idx] += 1
        
        // 处理未对齐的位置并归一化
        counts[counts == 0] = 1  // 避免除以零
        aligned /= counts[:, 新轴]
        
        返回 aligned
    
    标准化(序列):
        mean = 平均值(序列, 轴=0)
        std = 标准差(序列, 轴=0)
        返回 (序列 - mean) / (std + 1e-8)
    
    处理(序列):
        processed = 对齐序列(序列)
        返回 标准化(processed)

// 实时检测器类
类 实时检测器:
    初始化():
        model = tf.keras.模型.加载模型(CONFIG["model_path"])
        face_mesh = mp.解决方案.面部网格.面部网格(
            static_image_mode=假,
            max_num_faces=1,
            refine_landmarks=CONFIG["use_refined_landmarks"],
            min_detection_confidence=0.5)
        processor = 序列处理器()
        buffer = []
    
    检测(帧):
        // 转换颜色空间
        rgb_frame = cv2.转换颜色空间(帧, cv2.COLOR_BGR2RGB)
        
        // 检测面部关键点
        results = face_mesh.处理(rgb_frame)
        若 不是 results.multi_face_landmarks 存在:
            返回 帧, 空
        
        // 提取特征
        landmarks = 数组([[lm.x, lm.y, lm.z]
                            对于 lm 在 results.multi_face_landmarks[0].地标]):
        buffer.添加(landmarks.展平())
        
        // 保持缓冲区长度
        若 长度(buffer) > CONFIG["target_length"]:
            buffer = buffer[-CONFIG["target_length"]:]
        
        // 达到最小帧数开始预测
        若 长度(buffer) >= CONFIG["min_frames"]:
            尝试:
                processed = processor.处理(数组(buffer))
                pred = model.预测(processed[新轴, ...], 详细=0)[0]
                label_idx = 最大值索引(pred)
                返回 帧, 类[label_idx]
            除了 异常 as e:
                打印(f"预测错误: {str(e)}")
                加载标签()
                返回 帧, 空
        
        返回 帧, 空

// 实时演示函数
实时演示():
    detector = 实时检测器()
    
    // 打开摄像头
    cap = cv2.视频捕获(0)
    cv2.命名窗口("微表情检测", cv2.窗口_正常)
    
    start_time = 时间.时间()
    counter = 0
    
    当 真 时:
        ret, frame = cap.读取()
        若 不是 ret:
            跳出循环
        
        counter += 1  // 计算帧数
        // 处理帧并显示结果
        processed_frame, pred = detector.检测(frame)
        若 pred 存在:
            cv2.添加文字(processed_frame, f"预测: {pred}", (20, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        若 (时间.时间() - start_time) != 0:  // 实时显示帧数
            cv2.添加文字(frame, "FPS {0}".格式(浮点('%.1f' % (counter / (时间.时间() - start_time)))), (5, 400),
                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255),
                    3)
            // 打印("FPS: ", counter / (时间.时间() - start_time))
            counter = 0
            start_time = 时间.时间()
        cv2.显示("微表情检测", processed_frame)
        
        // 退出键
        若 cv2.等待键(1) & 0xFF == ord('q'):
            跳出循环
    
    cap.释放()
    cv2.销毁所有窗口()

// 加载标签函数
加载标签():
    全局 类  // 声明为全局变量以便其他函数使用
    
    categories = 排序([d 对于 d 在 列表目录(CONFIG["data_dir"])
                        若 os.路径.是目录(连接路径(CONFIG["data_dir"], d))])
    label_encoder = 标签编码器().拟合(categories)
    类 = label_encoder.类_

// 主执行流程
主函数():
    // 加载类别标签
    加载标签()
    
    // 运行实时检测
    实时演示()
